Table 1: Choosing Backbone Models for the Ensemble-Based Ranking Filter. 

|   | hit@1 | hit@5 | hit@10 | hit@20 | hit@30|
|----------|----------|----------|----------|----------|----------|
| BERT | 0.1451 | 0.5078 | 0.7677 | 0.9431 | 0.9871 | 
| RoBERTa | 0.1020 | 0.3865 | 0.6666| 0.9236 | 0.9807 |
| SciBERT | 0.1654 | 0.5093  | 0.7541 | 0.9564 | 0.9896 |

Table 2: Evaluating Prompt Sensitivity within the DBLP Taxonomy. Due to GPT-4's inability to interpret TaxonomyGPT instructions, all findings are derived from experiments conducted with GPT-3.5.

| TaxonomyGPT| edge       |            |            | ancestor   |            |            |
|-----------|------------|------------|------------|------------|------------|------------|
| # of demo | precision | recall     | f1         | precision  | recall     | f1         |
| 1         | 0.2527     | 0.1976     | 0.2216     | 0.2331     | 0.1218     | 0.1582     |
| 2         | 0.2286     | 0.2106     | 0.2188     | 0.2003     | 0.1451     | 0.1674     |
| 3         | 0.2095     | 0.1663     | 0.1843     | 0.1800     | 0.1060     | 0.1331     |
| 4         | 0.2095     | 0.1486     | 0.1732     | 0.2096     | 0.1027     | 0.1363     |
| 5         | 0.3427     | 0.2217     | 0.2597     | 0.2898     | 0.1440     | 0.1715     |

| CoL       | edge       |            |            | ancestor   |            |            |
|-----------|------------|------------|------------|------------|------------|------------|
| # of demo | precision | recall     | f1         | precision  | recall     | f1         |
| 1         | 0.4089     | 0.1852     | 0.233      | 0.8451     | 0.3333     | 0.4451     |
| 2         | 0.3609     | 0.1796     | 0.2336     | 0.7697     | 0.3162     | 0.426      |
| 3         | 0.3977     | 0.2725     | 0.3207     | 0.8552     | 0.4791     | 0.6064     |
| 4         | 0.4438     | 0.2862     | 0.3371     | 0.721      | 0.461      | 0.5459     |
| 5         | 0.5535     | 0.2870     | 0.3766     | 0.7974     | 0.4221     | 0.5476     |

| CoL-Zero  | edge       |            |            | ancestor   |            |            |
|-----------|------------|------------|------------|------------|------------|------------|
| # of demo | precision | recall     | f1         | precision  | recall     | f1         |
| 1         | 0.5955     | 0.1864     | 0.2782     | 0.7892     | 0.2281     | 0.3399     |
| 2         | 0.3963     | 0.1774     | 0.2367     | 0.6595     | 0.2708     | 0.3664     |
| 3         | 0.6597     | 0.1527     | 0.2166     | 0.8216     | 0.2126     | 0.3013     |
| 4         | 0.7441     | 0.3538     | 0.4475     | 0.8704     | 0.3948     | 0.5054     |
| 5         | 0.5372     | 0.3061     | 0.3802     | 0.7678     | 0.3839     | 0.4936     |

Table 3: Performance Comparison of TaxonomyGPT and CoL Using LLaMa-2-Chat-70B

|              | Edge            |              |        | Ancestor      |              |        | 
|--------------|-----------------|--------------|--------|---------------|--------------|--------------|
|              | Precision       | Recall       | F1     | Precision     | Recall       | F1     |
| **Wordnet**  |                 |              |        |               |              |        |
| CoL          | 0.1955          | 0.1757       | 0.1804 | 0.4449        | 0.2658       | 0.3209 |
| TaxonomyGPT  | 0.0099          | 0.0087       | 0.0092 | 0.0162        | 0.0117       | 0.0131 |
| **Wiki**     |                 |              |        |               |              |        |
| CoL          | 0.8             | 0.3463       | 0.4824 | 0.8           | 0.338        | 0.4742 |
| TaxonomyGPT  | 0               | 0            | 0      | 0             | 0            | 0      |
| **DBLP**     |                 |              |        |               |              |        |
| CoL          | 0.3076          | 0.1189       | 0.1657 | 0.6503        | 0.2373       | 0.3399 |
| TaxonomyGPT  | 0.0966          | 0.0894       | 0.0928 | 0.1341        | 0.117        | 0.125  |
| **SemEval-Sci** |              |              |        |               |              |        |
| CoL          | 0.36            | 0.1324       | 0.1931 | 0.6924        | 0.1268       | 0.2135 |
| TaxonomyGPT  | 0               | 0            | 0      | 0             | 0            | 0      |

Table 4: Performance of the CTP Model with LLaMa-2-7B as the Backbone Across Four Benchmark Taxonomies
|              | Edge            |              |        | Ancestor      |              |        | 
|--------------|-----------------|--------------|--------|---------------|--------------|--------------|
|              | Precision       | Recall       | F1     | Precision     | Recall       | F1     |
| **WordNet**  | 0.  | 0.| 0.| 0.| 0.  | 0.|
| **Wiki**     | 0.6364  | 0.6007| 0.6180| 0.| 0.  | 0.| 
| **DBLP**     | 0.4439  | 0.3581 | 0.3964 | 0.4873| 0.3988  | 0.4386|
| **SemEval-Sci**     | 0.4833  | 0.4192 | 0.4490 | 0.6198| 0.5409  | 0.5777 |   



Table 5: Performance of CoL with Top-K Entities Retained by the Ensemble-Based Ranking Filter

| CoL        | wiki    |       |       |       |         |       |    
|------------|---------|-------|-------|-------|---------|-------|
|            | p_e     | r_e   | f_e   | p_a   | r_a     | f_a   | 
| **top10**  | 0.9792  | 0.9499| 0.9643| 0.9917| 0.9599  | 0.9754|
| **top15**  | 0.9590  | 0.8696| 0.9104| 0.9855| 0.8972  | 0.9373| 
| **top20**  | 0.9786  | 0.916 | 0.9448| 0.9891| 0.9313  | 0.9579|   

| CoL        | DBLP    |       |       |       |         |       |    
|------------|---------|-------|-------|-------|---------|-------|
|            | p_e     | r_e   | f_e   | p_a   | r_a     | f_a   | 
| **top10**  | 0.5507  | 0.4427| 0.4796| 0.7995| 0.6306  | 0.6882| 
| **top15**  | 0.5067  | 0.4333| 0.4654| 0.7390| 0.6500  | 0.6886| 
| **top20**  | 0.5891  | 0.3766| 0.4343| 0.7826| 0.4961  | 0.5787|    


| CoL        | SemEval-Sci    |       |       |       |     |    |    
|------------|---------|-------|-------|-------|---------|-------|
|            | p_e     | r_e   | f_e   | p_a   | r_a     | f_a   | 
| **top10**  | 0.5422  | 0.4975| 0.5186| 0.8629| 0.5374  | 0.6597| 
| **top15**  | 0.5767  | 0.4885| 0.5283| 0.8857| 0.4831  | 0.6235| 
| **top20**  | 0.6098  | 0.3582| 0.4308| 0.9274| 0.3398  | 0.4762|     

Table 6: Analysis of Token Consumption on WordNet

| Model               | Total Prompt Tokens | Total Completion Tokens | Total Tokens |
|---------------------|---------------------|-------------------------|--------------|
| CoL (gpt-3.5)       | 2,404,927           | 32,620                  | 2,437,547    |
| TaxonomyGPT (gpt-3.5) | 178,503           | 20,015                  | 198,518      |


Table 7: Performance of Ensemble-Based Content Filtering for Taxonomy Induction Across Four Benchmark Taxonomies

|              | Hit@1            |
|--------------|-----------------|
| **WordNet**  | 0.1774 |
| **Wiki**     | 0.1168 |
| **DBLP**     | 0.0000 |
| **SemEval-Sci**     | 0.0070 | 
